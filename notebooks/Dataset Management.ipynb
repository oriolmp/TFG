{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "65082436",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as T\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c873b3-50d9-4747-aa58-89bde757f880",
   "metadata": {},
   "source": [
    "Here we want to create a validation set from the train set. We want a 85% train and 15%, keeping the labels proportionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51dda77-6258-4cb4-8695-d8f1b2fb8c3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TRAIN_CSV = 'EPIC_100_train.csv'\n",
    "VAL_CSV = 'EPIC_100_validation.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad419d5-97b1-4552-b535-3c53d8782433",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Original df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cad68d4-4b22-4cf1-914d-cd10b1128366",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(TRAIN_CSV)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc56146-54be-4ec3-aa34-913d86bd1ceb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6444338-ab37-4f30-9376-0dcea1929738",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['verb_class'].apply(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f4c819-d23e-4bac-b3a6-229816b355a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.drop(df[df['video_id'] == 'P23_04'].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce7f1ff-099b-4d90-a0d8-f17c2fee64cf",
   "metadata": {},
   "source": [
    "## Create splits and new train/val dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e585c22f-a0b6-48e0-b325-323da7d87e03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "verbs = df['verb_class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9626f649-9ae5-4242-87d0-01c70defc5f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_verb_train_list = []\n",
    "df_verb_val_list = []\n",
    "for verb in verbs:\n",
    "    if len(df[df['verb_class'] == verb]) >= 2:\n",
    "        df_verb = df[df['verb_class'] == verb]\n",
    "        df_verb_train, df_verb_val = train_test_split(df_verb, test_size=0.15, train_size=0.85, random_state=1, shuffle=True)\n",
    "        df_verb_train_list.append(df_verb_train)\n",
    "        df_verb_val_list.append(df_verb_val)\n",
    "    else:\n",
    "        print(f'verb {verb} skipped. Only {len(df[df[\"verb_class\"] == verb])} values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce179f14-639a-4f34-bfdf-70debd4f63dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train = pd.concat(df_verb_train_list)\n",
    "df_val = pd.concat(df_verb_val_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd49d52-c073-4926-a51e-109470544ad4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train['verb_class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23ff1d8-95dc-442c-a19d-1f6f70dc3ca4",
   "metadata": {},
   "source": [
    "We have to make the classes to be in order of [0, 1, 2, .., 96]. Now in the last labels we have [0, ..., 92, 94, 95, 96] which raises an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2760a7b-79b2-475e-8b96-1f1e29e35336",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for num in [94, 95, 96]:\n",
    "    for index in df_train['verb_class'][df_train['verb_class'] == num].index:\n",
    "        df_train.loc[index, 'verb_class'] = num-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22992d3-2ff7-4dbb-ad14-41280d71446c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for num in [94, 95, 96]:\n",
    "    for index in df_val['verb_class'][df_val['verb_class'] == num].index:\n",
    "        df_val.loc[index, 'verb_class'] = num-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff3decb-9a31-4c05-8a8b-c7105ba0ff50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train['verb_class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b19be4c-08e1-488f-b352-82356926c2fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_val['verb_class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68339e1-e008-484b-ba4d-948739430a0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# shuffle the rows\n",
    "df_train = df_train.sample(frac = 1)\n",
    "df_val = df_val.sample(frac = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06de6c6a-5387-4fe4-8370-f1fbaadfe770",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f'df train shape: {df_train.shape}')\n",
    "print(f'df val shape: {df_val.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d113d7-e630-41e6-b3cf-66f0bb966884",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train['verb_class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452b16a8-4d82-46c8-879c-e8bd9b4910af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_val['verb_class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe090e0f-aba0-4ab6-a1a4-bccf713990d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a31d504-8c66-4458-a08c-1ebb3d752160",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train.to_csv('train.csv')\n",
    "df_val.to_csv('val.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c7a3f5-83f5-4f13-b512-268e6df9f729",
   "metadata": {},
   "source": [
    "## weight for classes exporation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a52eda6-214a-4525-bf43-c799d3438daf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unique_labels = np.array(df_train['verb_class'].unique())\n",
    "unique_labels.sort()\n",
    "all_labels = np.array(df_train['verb_class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543cdaea-c256-492c-af74-e3db4df133c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbb52ef-5807-4ab4-bbbd-f520313699b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d054e7fb-fcfd-48d1-9812-4cb69b3e9e29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class_weights = compute_class_weight(class_weight='balanced', classes=unique_labels, y=all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d7a46e-b96f-4c14-845a-518874e9d5e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1745639f-564e-4beb-91f6-c0a98f053307",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4ffbb4-a5b0-42b5-a232-4704c432e90d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class_weights_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb0937a-05d3-4169-af07-1f9c5b270460",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(weight=class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82724b8c-07a4-4fba-bfe6-be7670bdb3df",
   "metadata": {},
   "source": [
    "Image reshape and save to another dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3bc4eb-a0e2-407a-b7d3-b423e00cf27a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc70fb9-c383-4717-b012-efb4f0d89fdf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "frame = Image.open('frame_0000042685.jpg')\n",
    "frame.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd318ef-a70f-4736-b075-353810ddd77e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_path = 'sample_image.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89b3c4c-e1b5-40ce-9234-175e0b3e2460",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img = Image.open(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f338e9-fe6a-4f28-8e0f-4cedb141479c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422ee9c7-edc0-40a8-bb5b-d0e2caadbf45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "resize = T.Resize(size=(100, 100), antialias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17424e1d-ff8a-48b3-b144-3136bb130a62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_resize = resize(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0018266b-b988-45a7-b01a-bebb56370422",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_resize = img.resize(size=(100, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de5cfca-c900-4765-b6c3-7525fbc46a29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_resize.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a045110-a967-40f7-b94d-db3affc99423",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2166ea77-5062-495d-99ca-2bccdc2df296",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "root = os.getcwd()\n",
    "root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57970145-3b39-4103-aad6-95073c4e4902",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_resize.save(r\"C:\\Users\\34609\\VisualStudio\\TFG\\sample.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c435d2b-3b38-4191-b63d-04140e51cb57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dirs = os.listdir(r\"C:\\Users\\34609\\VisualStudio\\TFG\")\n",
    "dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac958c47-c298-4299-8433-0bd2c48d45cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "joined = os.path.join(\"C:/Users/34609/VisualStudio/TFG/\", dirs[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d557855-a803-4939-87b9-35a872ab4b28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3753fca1-7b7d-43c5-810b-a84c8327aec7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.mkdir(r'C:\\Users\\34609\\VisualStudio\\TFG\\samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecadc7b-ebb0-44c9-ab8a-2f762b8d7cee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.isdir(r'C:\\Users\\34609\\VisualStudio\\TFG'):\n",
    "    print('Yes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca63382-dcd5-485d-a4f7-98d92cbccf5f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load image with pyvips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9c26b07-d65d-4a87-bec4-6cc76170b229",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "vipshome = 'c:\\\\vips-dev-8.7\\\\bin'\n",
    "os.environ['PATH'] = vipshome + ';' + os.environ['PATH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96af3781-648f-4e8a-80e8-024b958a007c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "cannot load library 'libgobject-2.0-0.dll': error 0x7e.  Additionally, ctypes.util.find_library() did not manage to locate a library called 'libgobject-2.0-0.dll'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pyvips\\__init__.py:19\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 19\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01m_libvips\u001b[39;00m\n\u001b[0;32m     21\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoaded binary module _libvips\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named '_libvips'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyvips\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pyvips\\__init__.py:70\u001b[0m\n\u001b[0;32m     67\u001b[0m     _gobject_libname \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlibgobject-2.0.so.0\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# possibly use ctypes.util.find_library() to locate the lib?\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m gobject_lib \u001b[38;5;241m=\u001b[39m \u001b[43mffi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_gobject_libname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     71\u001b[0m vips_lib \u001b[38;5;241m=\u001b[39m ffi\u001b[38;5;241m.\u001b[39mdlopen(_vips_libname)\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _glib_libname:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\transformer_venv\\lib\\site-packages\\cffi\\api.py:150\u001b[0m, in \u001b[0;36mFFI.dlopen\u001b[1;34m(self, name, flags)\u001b[0m\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdlopen(name): name must be a file name, None, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    148\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor an already-opened \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvoid *\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m handle\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m--> 150\u001b[0m     lib, function_cache \u001b[38;5;241m=\u001b[39m \u001b[43m_make_ffi_library\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_caches\u001b[38;5;241m.\u001b[39mappend(function_cache)\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libraries\u001b[38;5;241m.\u001b[39mappend(lib)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\transformer_venv\\lib\\site-packages\\cffi\\api.py:832\u001b[0m, in \u001b[0;36m_make_ffi_library\u001b[1;34m(ffi, libname, flags)\u001b[0m\n\u001b[0;32m    830\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_make_ffi_library\u001b[39m(ffi, libname, flags):\n\u001b[0;32m    831\u001b[0m     backend \u001b[38;5;241m=\u001b[39m ffi\u001b[38;5;241m.\u001b[39m_backend\n\u001b[1;32m--> 832\u001b[0m     backendlib \u001b[38;5;241m=\u001b[39m \u001b[43m_load_backend_lib\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlibname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    833\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    834\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21maccessor_function\u001b[39m(name):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\transformer_venv\\lib\\site-packages\\cffi\\api.py:827\u001b[0m, in \u001b[0;36m_load_backend_lib\u001b[1;34m(backend, name, flags)\u001b[0m\n\u001b[0;32m    825\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m first_error \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    826\u001b[0m         msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.  Additionally, \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (first_error, msg)\n\u001b[1;32m--> 827\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(msg)\n\u001b[0;32m    828\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mload_library(path, flags)\n",
      "\u001b[1;31mOSError\u001b[0m: cannot load library 'libgobject-2.0-0.dll': error 0x7e.  Additionally, ctypes.util.find_library() did not manage to locate a library called 'libgobject-2.0-0.dll'"
     ]
    }
   ],
   "source": [
    "import pyvips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9988a4-558f-4401-b7e7-dafd71d52a9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip uninstall pyvips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7907ffe-68b8-42bc-8810-54662f2fe0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = pyvips.Image.new_from_file('some-image.jpg')\n",
    "a1 = image.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a93f009-89e3-4b8c-b3b3-b146229f4a22",
   "metadata": {},
   "source": [
    "## Load image with opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4ddc372-ba5d-4124-9b41-971835874836",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bec0f2e1-3f3f-412c-bb29-582d0b2c94d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "arr = cv2.imread('frame_0000042685.jpg', cv2.IMREAD_UNCHANGED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "67d94fed-0212-47bb-ba51-a844ff7b158a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 256, 3)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a381fb46-2ca0-4c61-8e53-924473cb86ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "to_tensor = T.ToTensor()\n",
    "resize = T.Resize(size=(112, 112), antialias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "24be992f-d6e2-4ddb-8cec-6a8c83d92592",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img = to_tensor(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ea6bdeba-bc38-4ce3-b5b4-bde5083b44bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "frames = [resize(img).unsqueeze(-1) for i in range(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b9395217-2e24-492b-96b2-4003d7c1f012",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clip = torch.cat(frames, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "589c0c60-f9d9-4688-861b-2fcb2d06662c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 112, 112, 100])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clip.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "45811930-bb3e-4839-88b6-80c3aca0c635",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 50)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad = (50, 50)\n",
    "pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7e71e554-8968-4260-b4fe-c26e2d09dae4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clip_padded = nn.functional.pad(clip, pad, 'constant', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a58a8e7d-61d0-4c72-9b01-8b2377704549",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 112, 112, 200])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clip_padded.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "99e317cc-4168-4eda-8781-3882e44e5843",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200, 3, 112, 112])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clip_2 = rearrange(clip_padded, 'c w h t1 -> t1 c w h')\n",
    "clip_2.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "1030edb0-a269-48e5-b8b5-b40242e91e13",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 3, 112, 112])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clip_3 = clip_2[0:200:2] # take 1 for every 2 frames\n",
    "clip_3.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a3f0b3bc-80ac-43dd-93a0-e2082ebd957b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([112, 112, 200, 3])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clip_4 = rearrange(clip_3, 't2 c w h -> c w h t2') \n",
    "clip_4.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "00438ef7-b87c-4b22-8d28-49b178732d52",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "random_ expects 'from' to be less than 'to', but got from=0 >= to=0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhigh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: random_ expects 'from' to be less than 'to', but got from=0 >= to=0"
     ]
    }
   ],
   "source": [
    "x = torch.randint(low=0, high=0, size=(1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2449ff5-b244-49a3-8ec7-471849f1bb4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
